{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse = \"/home/phuc/Practice/DataScience/DSProject/data/warehouse\"\n",
    "warehouse_df = spark.read.format(\"delta\").load(warehouse)\n",
    "warehouse_df = warehouse_df.toPandas()\n",
    "warehouse_df.to_csv(\"/home/phuc/Practice/DataScience/DSProject/data/job.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11277"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_path = \"/home/phuc/Practice/DataScience/DSProject/data/raw/careerlink/2023-12-17T03-36-11+00-00.csv\"\n",
    "job_df = spark.read.csv(job_path, header=True)\n",
    "job_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- post_id: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- job_listed: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- job_deadline: string (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- job_address: string (nullable = true)\n",
      " |-- job_experience_requied: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_function: string (nullable = true)\n",
      " |-- education_level: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Industries: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- skill: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and ingest into delta lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable\n",
    "from delta import *\n",
    "from job_transformation.careerlink.convert_job_listed_to_datetime import convert_to_job_listed_datetime\n",
    "from job_transformation.careerlink.extract_job_address import extract_job_address\n",
    "from job_transformation.careerlink.extract_job_deadline_date import extract_job_deadline_date\n",
    "from job_transformation.careerlink.modify_company_name import modify_company_name\n",
    "from job_transformation.careerlink.modify_job_title import modify_job_title\n",
    "from job_transformation.careerlink.normalize_employment_type import normalize_employment_type\n",
    "from job_transformation.careerlink.normalize_industries import normalize_industries\n",
    "from job_transformation.careerlink.normalize_job_function import normalize_job_function\n",
    "from job_transformation.careerlink.extract_min_max_salary import extract_min_max_salary\n",
    "from job_transformation.careerlink.extract_min_max_yoe import extract_min_max_yoe\n",
    "from utils.merge_schema import merge_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = spark.read.csv(job_path, header=True).limit(100)\n",
    "job_df = job_df.withColumn(\"company_name\", modify_company_name(job_df[\"company_name\"]))\n",
    "job_df = job_df.withColumn(\"job_title\", modify_job_title(job_df[\"job_title\"]))\n",
    "job_df = job_df.withColumn(\"job_listed\", convert_to_job_listed_datetime(job_df[\"job_listed\"]))\n",
    "job_df = job_df.withColumn(\"job_address\", extract_job_address(job_df[\"job_address\"]))\n",
    "job_df = job_df.withColumn(\"job_deadline\", extract_job_deadline_date(job_df[\"job_deadline\"]))\n",
    "job_df = job_df.withColumn(\"employment_type\", normalize_employment_type(job_df[\"employment_type\"]))\n",
    "job_df = job_df.withColumn(\"job_level\", normalize_job_function(job_df[\"job_function\"])).drop(\"job_function\")\n",
    "job_df = job_df.withColumn('industry', normalize_industries(job_df[\"Industries\"])).drop(\"Industries\")\n",
    "job_df = extract_min_max_yoe(job_df, \"job_experience_requied\", \"job_yoe_min\", \"job_yoe_max\")\n",
    "job_df = extract_min_max_salary(job_df, \"salary\", \"salary_min\", \"salary_max\")\n",
    "job_df = job_df.withColumn(\"ingested_at\", F.current_date())\n",
    "job_df = job_df.withColumn(\"updated_at\", F.current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+-------------------+------------+--------------------+-----------------+----------------------+---------------+-------------------+--------+--------------------+--------------------+---------+--------------------+-----------+-----------+----------+----------+-----------+----------+\n",
      "|post_id|           job_title|job_listed|             salary|job_deadline|        company_name|      job_address|job_experience_requied|employment_type|    education_level|  gender|     job_description|               skill|job_level|            industry|job_yoe_min|job_yoe_max|salary_min|salary_max|ingested_at|updated_at|\n",
      "+-------+--------------------+----------+-------------------+------------+--------------------+-----------------+----------------------+---------------+-------------------+--------+--------------------+--------------------+---------+--------------------+-----------+-----------+----------+----------+-----------+----------+\n",
      "|2733613|Sales Executive -...|2023-12-16|       Thương lượng|  2024-01-16|   Biển Ngọc Hồ Tràm|Bà Rịa - Vũng Tàu|          Thương lượng|      full time|           Cao đẳng|Nam / Nữ|- Actively sell a...|- College or bach...|Nhân viên|Finance and economic|       NULL|       NULL|      NULL|      NULL| 2023-12-17|2023-12-17|\n",
      "|2733592|Nhân Viên Kinh Do...|2023-12-16|         Cạnh tranh|  2024-01-16|Uni-President Việ...|          Bến Tre|                  NULL|      full time|          Trung cấp|     Nam|- Liên hệ, tìm ki...|- Nam, - Tốt nghi...|Nhân viên|         Hospitality|       NULL|       NULL|      NULL|      NULL| 2023-12-17|2023-12-17|\n",
      "|2733584|     Trưởng Phòng It|2023-12-16|       Thương lượng|  2024-01-16|       Sbay Việt Nam|          Đà Nẵng|  2 - 5 năm kinh ng...|      full time|            Cử nhân|Nam / Nữ|- VP Đà Nẵng: 03 ...|- Có kinh nghiệm ...|  Quản lý|Computer and tech...|          2|          5|      NULL|      NULL| 2023-12-17|2023-12-17|\n",
      "|2732979|Nam Từ Liêm, Hà N...|2023-12-15|10 triệu - 20 triệu|  2024-01-15|            Manulife|           Hà Nội|  1 - 2 năm kinh ng...|      full time|          Nhân viên|Nam / Nữ|- Là đại diện của...|- Trình độ: Cao đ...|Nhân viên|Finance and economic|          1|          2|  10000000|  20000000| 2023-12-17|2023-12-17|\n",
      "|2733598|Nhân Viên Tư Vấn ...|2023-12-16|  5 triệu - 9 triệu|  2024-01-16|Bán Lẻ Kỹ Thuật S...|          Đắk Lắk|  0 - 1 năm kinh ng...|      full time|Trung học phổ thông|Nam / Nữ|- Chủ động đón ti...|- Nam/Nữ, tuổi từ...|Nhân viên|         Hospitality|          0|          1|   5000000|   9000000| 2023-12-17|2023-12-17|\n",
      "+-------+--------------------+----------+-------------------+------------+--------------------+-----------------+----------------------+---------------+-------------------+--------+--------------------+--------------------+---------+--------------------+-----------+-----------+----------+----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/17 11:28:10 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ingest_table = \"/home/phuc/Practice/DataScience/DSProject/data/ingestion/careerlink\"\n",
    "\n",
    "\n",
    "if DeltaTable.isDeltaTable(spark, ingest_table):\n",
    "    deltaTable = DeltaTable.forPath(spark, ingest_table)\n",
    "    print(type(deltaTable))\n",
    "    deltaTable, job_df = merge_schema(spark, deltaTable, job_df)\n",
    "    print(job_df.count())\n",
    "    delta_df = deltaTable.toDF()\n",
    "    print(delta_df.count())\n",
    "\n",
    "    cols = {}\n",
    "    for col in job_df.columns:\n",
    "        if col == \"ingested_at\":\n",
    "            continue\n",
    "        cols[col] = F.when(job_df[col].isNotNull(), job_df[col]).otherwise(delta_df[col])\n",
    "        \n",
    "    deltaTable.alias('ingestion_table').merge(\n",
    "        job_df.alias('daily_table'),\n",
    "        'ingestion_table.post_id = daily_table.post_id'\n",
    "    ).whenNotMatchedInsertAll().whenMatchedUpdate(set=cols).execute()\n",
    "    \n",
    "else:\n",
    "    job_df.write.format(\"delta\").save(ingest_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/12/17 11:26:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "from job_transformation.careerlink.transformation_and_ingestion import transform_and_ingest\n",
    "\n",
    "daily_table = \"/home/phuc/Practice/DataScience/DSProject/data/raw/careerlink/2023-12-17T03-36-11+00-00.csv\"\n",
    "ingest_table = \"/home/phuc/Practice/DataScience/DSProject/data/ingestion/careerlink\"\n",
    "\n",
    "transform_and_ingest(\n",
    "    daily_table=daily_table,\n",
    "    ingest_table=ingest_table\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingest_df = spark.read.format(\"delta\").load(\"/home/phuc/Practice/DataScience/DSProject/data/ingestion/careerlink\")\n",
    "ingest_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- post_id: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- job_listed: date (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- job_deadline: date (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- job_address: string (nullable = true)\n",
      " |-- job_experience_requied: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- education_level: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- skill: string (nullable = true)\n",
      " |-- job_level: string (nullable = true)\n",
      " |-- industry: string (nullable = true)\n",
      " |-- job_yoe_min: integer (nullable = true)\n",
      " |-- job_yoe_max: integer (nullable = true)\n",
      " |-- salary_min: integer (nullable = true)\n",
      " |-- salary_max: integer (nullable = true)\n",
      " |-- ingested_at: date (nullable = true)\n",
      " |-- updated_at: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ingest_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+-------------------+------------+--------------------+-----------------+----------------------+---------------+-------------------+--------+--------------------+--------------------+---------+--------------------+-----------+-----------+----------+----------+-----------+----------+\n",
      "|post_id|           job_title|job_listed|             salary|job_deadline|        company_name|      job_address|job_experience_requied|employment_type|    education_level|  gender|     job_description|               skill|job_level|            industry|job_yoe_min|job_yoe_max|salary_min|salary_max|ingested_at|updated_at|\n",
      "+-------+--------------------+----------+-------------------+------------+--------------------+-----------------+----------------------+---------------+-------------------+--------+--------------------+--------------------+---------+--------------------+-----------+-----------+----------+----------+-----------+----------+\n",
      "|2733613|Sales Executive -...|2023-12-16|       Thương lượng|  2024-01-16|   Biển Ngọc Hồ Tràm|Bà Rịa - Vũng Tàu|          Thương lượng|      full time|           Cao đẳng|Nam / Nữ|- Actively sell a...|- College or bach...|Nhân viên|Finance and economic|       NULL|       NULL|      NULL|      NULL| 2023-12-17|2023-12-17|\n",
      "|2733592|Nhân Viên Kinh Do...|2023-12-16|         Cạnh tranh|  2024-01-16|Uni-President Việ...|          Bến Tre|                  NULL|      full time|          Trung cấp|     Nam|- Liên hệ, tìm ki...|- Nam, - Tốt nghi...|Nhân viên|         Hospitality|       NULL|       NULL|      NULL|      NULL| 2023-12-17|2023-12-17|\n",
      "|2733584|     Trưởng Phòng It|2023-12-16|       Thương lượng|  2024-01-16|       Sbay Việt Nam|          Đà Nẵng|  2 - 5 năm kinh ng...|      full time|            Cử nhân|Nam / Nữ|- VP Đà Nẵng: 03 ...|- Có kinh nghiệm ...|  Quản lý|Computer and tech...|          2|          5|      NULL|      NULL| 2023-12-17|2023-12-17|\n",
      "|2732979|Nam Từ Liêm, Hà N...|2023-12-15|10 triệu - 20 triệu|  2024-01-15|            Manulife|           Hà Nội|  1 - 2 năm kinh ng...|      full time|          Nhân viên|Nam / Nữ|- Là đại diện của...|- Trình độ: Cao đ...|Nhân viên|Finance and economic|          1|          2|  10000000|  20000000| 2023-12-17|2023-12-17|\n",
      "|2733598|Nhân Viên Tư Vấn ...|2023-12-16|  5 triệu - 9 triệu|  2024-01-16|Bán Lẻ Kỹ Thuật S...|          Đắk Lắk|  0 - 1 năm kinh ng...|      full time|Trung học phổ thông|Nam / Nữ|- Chủ động đón ti...|- Nam/Nữ, tuổi từ...|Nhân viên|         Hospitality|          0|          1|   5000000|   9000000| 2023-12-17|2023-12-17|\n",
      "+-------+--------------------+----------+-------------------+------------+--------------------+-----------------+----------------------+---------------+-------------------+--------+--------------------+--------------------+---------+--------------------+-----------+-----------+----------+----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ingest_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
